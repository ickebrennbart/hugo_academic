<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nathalie Smuha | Leuven.AI Stories</title>
    <link>https://ai.kuleuven.be/stories/author/nathalie-smuha/</link>
      <atom:link href="https://ai.kuleuven.be/stories/author/nathalie-smuha/index.xml" rel="self" type="application/rss+xml" />
    <description>Nathalie Smuha</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 02 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ai.kuleuven.be/stories/media/logo_hu7e319e1ba8cd789af31f3b220e6aab0c_53539_300x300_fit_lanczos_2.png</url>
      <title>Nathalie Smuha</title>
      <link>https://ai.kuleuven.be/stories/author/nathalie-smuha/</link>
    </image>
    
    <item>
      <title>Europe as International Standard Setter for Artificial Intelligence: the role of the Council of Europe</title>
      <link>https://ai.kuleuven.be/stories/post/2021-04-10-cahai/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://ai.kuleuven.be/stories/post/2021-04-10-cahai/</guid>
      <description>&lt;p&gt;Increased awareness of AI’s risks when left unchecked – from discrimination to surveillance – has driven regulators across the world to work on AI-specific rules. Last year, the European Commission launched a &lt;a href=&#34;https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12270-White-Paper-on-Artificial-Intelligence-a-European-Approach/public-consultation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;public consultation&lt;/a&gt; about its &lt;a href=&#34;https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;White Paper on Artificial Intelligence&lt;/a&gt; published in February 2020, to which also Leuven.AI and CiTiP jointly responded. This year, on 30 March 2021, the Council of Europe’s &lt;a href=&#34;https://www.coe.int/en/web/artificial-intelligence/cahai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CAHAI&lt;/a&gt; launched a &lt;a href=&#34;https://www.coe.int/en/web/artificial-intelligence/cahai-multi-stakeholder-consultation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;call inviting stakeholders to provide feedback&lt;/a&gt; about its &lt;a href=&#34;https://rm.coe.int/cahai-2020-23-final-eng-feasibility-study-/1680a0c6da&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Feasibility Study&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and important regulatory choices to take with regard to artificial intelligence.&lt;/p&gt;
&lt;p&gt;Time to find out more about what kind of organisation the Council of Europe is, what it is doing in the area of AI, and why it is important to take part in the discussion! CiTiP’s &lt;a href=&#34;https://www.law.kuleuven.be/citip/en/staff-members/staff/00143950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eyup Kun&lt;/a&gt; had an interview with Leuven.AI members &lt;a href=&#34;https://ai.kuleuven.be/members/00018835&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Peggy Valcke&lt;/a&gt; and &lt;a href=&#34;https://ai.kuleuven.be/members/00117274&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nathalie Smuha&lt;/a&gt; about the Council of Europe and its activities in relation to AI.&lt;/p&gt;
&lt;div&gt;
  &lt;div style=&#34;width:33%; height:225px; float:left; text-align:left;&#34;&gt;
&lt;figure  id=&#34;figure-peggy-valcke&#34;&gt;
  &lt;div class=&#34;figure-img-wrap&#34; &gt;
      &lt;img alt=&#34;Peggy Valcke&#34; srcset=&#34;
             /stories/post/2021-04-10-cahai/valcke_hude62c9a716a0c4de80fd185dd8abe039_40225_3bc1ddda45615baa6ed9e785d2464820.jpeg 400w,
             /stories/post/2021-04-10-cahai/valcke_hude62c9a716a0c4de80fd185dd8abe039_40225_1f0d4023fd416e29bb5a0cb086e6343b.jpeg 760w,
             /stories/post/2021-04-10-cahai/valcke_hude62c9a716a0c4de80fd185dd8abe039_40225_1200x1200_fit_q75_lanczos.jpeg 1200w&#34;
             src=&#34;https://ai.kuleuven.be/stories/stories/post/2021-04-10-cahai/valcke_hude62c9a716a0c4de80fd185dd8abe039_40225_3bc1ddda45615baa6ed9e785d2464820.jpeg&#34;
             width=&#34;150px&#34;
             height=&#34;400&#34;
             loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&lt;figcaption&gt;
      Peggy Valcke
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
  &lt;div style=&#34;width:33%; height:225px; float:left; text-align:left;&#34;&gt;
&lt;figure  id=&#34;figure-nathalie-smuha&#34;&gt;
  &lt;div class=&#34;figure-img-wrap&#34; &gt;
      &lt;img alt=&#34;Nathalie Smuha&#34; srcset=&#34;
             /stories/post/2021-04-10-cahai/nathalie2_hu4f4b681310c338906a3eb826472b2fae_204261_e5d2b64f6212cb36005ab3cd2741a237.jpg 400w,
             /stories/post/2021-04-10-cahai/nathalie2_hu4f4b681310c338906a3eb826472b2fae_204261_edcb55bc2151ae3edadb13cd2d7fc008.jpg 760w,
             /stories/post/2021-04-10-cahai/nathalie2_hu4f4b681310c338906a3eb826472b2fae_204261_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
             src=&#34;https://ai.kuleuven.be/stories/stories/post/2021-04-10-cahai/nathalie2_hu4f4b681310c338906a3eb826472b2fae_204261_e5d2b64f6212cb36005ab3cd2741a237.jpg&#34;
             width=&#34;150px&#34;
             height=&#34;400&#34;
             loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&lt;figcaption&gt;
      Nathalie Smuha
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
  &lt;div style=&#34;width:33%; height:225px; float:left; text-align:right&#34;&gt;
&lt;figure  id=&#34;figure-eyup-kun&#34;&gt;
  &lt;div class=&#34;figure-img-wrap&#34; &gt;
      &lt;img alt=&#34;Eyup Kun&#34; srcset=&#34;
             /stories/post/2021-04-10-cahai/eyup_kun_hu0d930b7077cc615d9128e569aecf23d9_42303_cd217930f84e142e0aea500bf0936b2b.jpg 400w,
             /stories/post/2021-04-10-cahai/eyup_kun_hu0d930b7077cc615d9128e569aecf23d9_42303_729de6a6afbd9ef4181c5af45cfc41b0.jpg 760w,
             /stories/post/2021-04-10-cahai/eyup_kun_hu0d930b7077cc615d9128e569aecf23d9_42303_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
             src=&#34;https://ai.kuleuven.be/stories/stories/post/2021-04-10-cahai/eyup_kun_hu0d930b7077cc615d9128e569aecf23d9_42303_cd217930f84e142e0aea500bf0936b2b.jpg&#34;
             width=&#34;150px&#34;
             height=&#34;400&#34;
             loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&lt;figcaption&gt;
      Eyup Kun
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
Peggy, Nathalie, maybe we should start with what exactly is the Council of Europe and what is its role in relation to digital technologies such as AI?
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34; style=&#34;overflow:hidden&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Peggy:&lt;/span&gt; The Council of Europe is &lt;a href=&#34;https://www.coe.int/nl/web/about-us/do-not-get-confused&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;not to be confused with&lt;/a&gt; the European Council. The latter is an institution of the European Union, the economic and political union of 27 Member States on the continent. The former is actually Europe&amp;rsquo;s oldest political organisation and stands separate from the European Union; it was founded in 1949, in the aftermath of the Second World War. The Council of Europe’s mission is to protect human rights, democracy, and the rule of law in Europe. It currently consists of 47 member States (all Member States of the European Union, and other neighbouring countries such as the United Kingdom, Iceland, Liechtenstein, Norway, Russia, Armenia and Turkey). On the basis of discussion and collaboration among its member States, the Council of Europe can establish binding and non-binding legal instruments. Given that it is an international organisation, the binding nature of its legal instruments stems from states&#39; voluntary commitment to adopt, ratify, and transpose the treaties into their national law. Unlike the European Union, the Council of Europe cannot adopt legal rules that have immediate binding legal force throughout every Member State.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Nathalie:&lt;/span&gt;
The Council of Europe and its bodies have a significant impact on regulating the digital world from the standpoint of human rights. Firstly, The European Court of Human Rights considers &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2021836&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the European Convention on Human Rights (ECHR) as a living instrument&lt;/a&gt;. Although the Convention was established long before the digital revolution, the Court interprets it in a way that ensures consistent protection of human rights among its member states and applies these rights to the context of today. This type of evolutive interpretation allows the Court to include the “right to data protection” as part of the “right to a private life” under Article 8 of the Convention, considering the objective and values embedded under that Article. Also &lt;a href=&#34;https://www.echr.coe.int/documents/research_report_internet_eng.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the case-law of the Court on freedom of expression and access to information&lt;/a&gt; under Article 10 of the Convention continues to have an effect on the regulation of the digital media and access to the Internet among member States.&lt;/p&gt;
&lt;p&gt;In addition, in the digital field, the Council of Europe succeeded in the first binding international convention on data protection (&lt;a href=&#34;https://www.coe.int/en/web/data-protection/convention108/background&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Convention 108&lt;/a&gt;), which was opened for signature in 1981. This Convention and its modernised version, &lt;a href=&#34;https://www.coe.int/en/web/data-protection/convention108/modernised&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Convention 108+&lt;/a&gt;, aim to ensure safeguards for the protection of personal data and the right to privacy against the challenges of information technologies by providing high-level principles, including data minimisation, transparency and accountability, and by equipping individuals with data subject rights. With its non-binding instruments, the Committee of Ministers adopted &lt;a href=&#34;https://search.coe.int/cm/pages/result_details.aspx?objectid=09000016809e1154&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the recommendation&lt;/a&gt; on human rights impacts of algorithmic systems to the member States. The Consultative Committee of Convention 108 also provides specific guidelines on new regulatory challenges, such as &lt;a href=&#34;https://rm.coe.int/guidelines-on-facial-recognition/1680a134f3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;recent guidelines on facial recognition technology&lt;/a&gt;. The &lt;a href=&#34;https://www.coe.int/en/web/cybercrime/the-budapest-convention&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Budapest Convention on Cybercrime&lt;/a&gt; is another example of how the Council of Europe acts as a global standard-setting actor in the digital field.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
You are both very active within the Council of Europe’s CAHAI – what is CAHAI and what is precisely your role?
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Peggy:&lt;/span&gt;
The Ad hoc Committee on Artificial Intelligence (&lt;a href=&#34;https://www.coe.int/en/web/artificial-intelligence/cahai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CAHAI&lt;/a&gt;) was set up in September 2019 by the Committee of Ministers of the Council of Europe (one of its two governing bodies, besides the Parliamentary Assembly). It was tasked with the mission to examine the feasibility of a legal framework for AI systems (henceforth, Feasibility study) in line with the Council of Europe’s standards on human rights, democracy and the rule of law (see CAHAI’s &lt;a href=&#34;https://rm.coe.int/cahai-2020-2021-rev-en-pdf/16809fc157&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;terms of reference&lt;/a&gt;). It was stressed from the beginning that CAHAI would have to complement, and not duplicate, ongoing legislative efforts both within and outside the Council of Europe. So one of the first tasks that CAHAI took up was an exhaustive mapping of the various initiatives by other international and regional organisations, such as the European Union, the OECD, UNESCO, etc., as well as within the various Council of Europe bodies. CAHAI also collected information about relevant national initiatives. All this information is made available via CAHAI’s website (see &lt;a href=&#34;https://www.coe.int/en/web/artificial-intelligence/cahai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.coe.int/en/web/artificial-intelligence/national-initiatives&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;; also keep an eye out for the joint website that will show all initiatives at the &lt;a href=&#34;http://globalpolicy.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;global level&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Shortly after the launch of the Flemish Expert Centre on Data &amp;amp; Society, I was invited by the Flemish authorities to represent Belgium at CAHAI, together with a colleague representing Wallonia. During CAHAI’s first plenary meeting in November 2019, I was elected vice-chair, meaning that I also take part in bureau meetings, have regular contact with CAHAI’s secretariat and follow the various working groups set up within CAHAI from close by.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Nathalie:&lt;/span&gt;
Since Autumn 2020, I have served as an independent expert on AI policy and regulation to CAHAI. I provided expert guidance in the drafting process of the Feasibility Study, take part in plenary and working group meetings, and work closely with CAHAI’s secretariat for the activities of the Policy Development Group and Legal Frameworks Group. Prior to my involvement with the Council of Europe, I coordinated the work of the European Commission’s High-Level Expert Group on AI - an experience that has proven to be very useful in this context, which also evolves around AI policy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
&lt;p&gt;The &lt;a href=&#34;https://rm.coe.int/cahai-2020-23-final-eng-feasibility-study-/1680a0c6da&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Feasibility Study&lt;/a&gt; was adopted by CAHAI in December 2020 and marks an important milestone in its activities. What are important key take-aways?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Nathalie:&lt;/span&gt;
The feasibility study first touches upon opportunities and risks arising from the use of AI systems. In terms of opportunities, the study refers to the potential positive impact of AI in numerous domains, for instance by improving current industrial capabilities, the provision of healthcare and educational opportunities. Yet the scale of use of AI systems, and their opacity and complexity, can in some instances also amplify the risks inherent in human decision-making (like unjust biases for example) and cause new risks due to potential &amp;ldquo;vicious feedback loops”. The study therefore elaborates on how AI systems can impact human rights, democracy and the rule of law, taking the rights of the ECHR as a starting point.&lt;/p&gt;
&lt;p&gt;For instance, AI systems can pose a threat to the right to liberty and security (Article 5), the right to a fair trial (Article 6) and the right to an effective remedy (Article 13), when opaque systems are used in situations where freedom or personal security is at stake. The fact that they can facilitate or amplify unjust bias also poses a risk to the right to non-discrimination (Article 14). Furthermore, the right to privacy (Article 8) entails not only freedom from surveillance, but also the protection and enhancement of human autonomy. Being monitored indiscriminately by AI systems can steer people to think and behave in a specific way, impacting their autonomy. Due to the intrusive nature of some AI systems, especially online platforms for instance, freedom of expression (Article 10) and freedom of assembly and association (Article 11) are not unaffected either. These are just a few examples. Many of these rights are also closely related to safeguarding the integrity of the democratic process and the rule of law, which can hence also be negatively impacted.&lt;/p&gt;
&lt;p&gt;It’s however important to keep in mind that these risks depend on the application context, the type of technology used and the stakeholders involved. Not all AI systems pose the same type and level of risk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
How does the Feasibility Study propose to address these risks? What does it consider to be “main elements of a legal framework” for AI-systems?
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Peggy:&lt;/span&gt;
After analysing the benefits and risks of using AI systems, the feasibility study identifies principles that should be horizontally (i.e. irrespective of the sector or context) applicable to the design, development and use of AI systems. These principles are, among others, human dignity, human freedom and autonomy, non-discrimination, gender equality, fairness and diversity, accountability and transparency.  To operationalise these principles, the study matches them to corresponding concrete rights and obligations. The rights foreseen under the feasibility study are drawn from existing rights (the right to respect for private and family life), new rights tailored to challenges of AI systems (right to a meaning explanation of how AI system works) and clarification of existing rights (the right to physical, psychological and moral integrity in light of AI-based profiling and affect recognition). The feasibility study proposes how these obligations can be allocated to public and private actors, considering their uses and the different phases of AI application.&lt;/p&gt;
&lt;p&gt;In addition to setting principles and corresponding rights and obligations, the feasibility study, similar to the work of the High-Level Expert Group on AI (&lt;a href=&#34;https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60419&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;set up by the EU Commission&lt;/a&gt;), recommends a risk-based approach towards the regulation of AI systems. It highlights that the risk of AI systems varies depending on its context and sector used. A risk-based approach will help member states contextualise and set the risk level of AI systems in the different uses and provide tailored mechanisms for various risks identified. Where needed, the study also recommends that a more prudent precautionary approach (including potential prohibitions) should be considered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
What are the options for the Council of Europe Legal Framework according to the feasibility study?
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Nathalie:&lt;/span&gt;
After listing relevant principles, and potential rights and obligations, the feasibility study discusses the potential form of a future legal framework. The study considers the possibility of adopting binding and non-binding legal instruments and how they complement each other. It investigates the possibility of adding an extra protocol to the existing European Convention on Human Rights or to Convention 108+ on privacy, and the option to adopt a new binding convention. Both the advantages and possible shortcomings of all these options are explored, with the conclusion that mere voluntary guidelines are insufficient to protect people against AI’s risks.&lt;/p&gt;
&lt;p&gt;A legal framework should therefore include both legally binding and non-binding instruments to provide comprehensive protection and guidance, taking the specificities of different sectors and the risks and benefits of AI into account. Equally important, the study recommends practical mechanisms for compliance with the future legal framework, such as human rights impact assessments or auditing and certification mechanisms, as well as follow-up mechanisms and measures for international co-operation to guarantee the framework’s effectiveness.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;interview-questioner&#34;&gt;
Why should organisations like Leuven.AI participate in CAHAI’s multi-stakeholder consultation?
&lt;/div&gt;
&lt;div class=&#34;interview-left&#34;&gt;
&lt;p&gt;&lt;span class=&#34;interview-respondent&#34;&gt;Peggy &amp;amp; Nathalie:&lt;/span&gt;
The feedback from the consultation will directly inform CAHAI’s Legal Frameworks Group which is preparing input for a possible European Convention on AI. It is crucial to collect different perspectives, which will feed the ongoing discussion on the regulation of AI systems. Leuven.AI consists of people from different backgrounds, including computer engineers, neuroscientists, lawyers, philosophers, mathematicians. The perspective they bring can have a real impact on how international regulation of AI systems should look like. It is important to understand that such regulation should not be seen as hampering innovation, but as a means to steer innovation in the direction of socially responsible and desirable outcomes. Probably many of you have seen the 1993 movie “Jurrasic Park”? In a famous scene, Jeff Goldblum, who plays a chaos theory expert, tells the owner of a dinosaur theme park that&lt;/p&gt;
&lt;p class=&#34;quote&#34;&gt;
“your scientists were so preoccupied with whether or not they could [create dinosaurs from prehistoric DNA] that they didn’t stop to think if they should.”
&lt;/p&gt;
&lt;p&gt;Let’s take the time to reflect together on which AI applications we should and should not develop together…&lt;/p&gt;
&lt;/div&gt;  
&lt;div class=&#34;interview-questioner&#34; style=&#34;display:block&#34;&gt;
-- Eyup Kun
&lt;/div&gt;
&lt;p&gt;‌
‌
‌&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    In response to the open consultation process, Leuven.AI will organise a discussion to prepare our feedback to the CAHAI proposal. We strongly encourage all Leuven.AI researchers wanting to contribute to future standards of AI regulations to join this discussion. More details to follow soon on &lt;a href=&#34;https://ai.kuleuven.be/&#34;&gt;Leuven.AI&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;iframe id=&#34;kaltura_player&#34; src=&#34;https://cdnapisec.kaltura.com/p/2375821/sp/237582100/embedIframeJs/uiconf_id/43066731/partner_id/2375821?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_3one67yc&amp;flashvars[streamerType]=auto&amp;amp;flashvars[localizationCode]=en&amp;amp;flashvars[leadWithHTML5]=true&amp;amp;flashvars[sideBarContainer.plugin]=true&amp;amp;flashvars[sideBarContainer.position]=left&amp;amp;flashvars[sideBarContainer.clickToClose]=true&amp;amp;flashvars[chapters.plugin]=true&amp;amp;flashvars[chapters.layout]=vertical&amp;amp;flashvars[chapters.thumbnailRotator]=false&amp;amp;flashvars[streamSelector.plugin]=true&amp;amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;amp;flashvars[dualScreen.plugin]=true&amp;amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;amp;&amp;wid=1_0xao00c4&#34; width=&#34;0&#34; height=&#34;0&#34; allowfullscreen webkitallowfullscreen mozAllowFullScreen allow=&#34;autoplay *; fullscreen *; encrypted-media *&#34; sandbox=&#34;allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation&#34; frameborder=&#34;0&#34; title=&#34;Kaltura Player&#34;&gt;&lt;/iframe&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;For an accessible introduction to CAHAI’s Feasibility Study, you can consult the &lt;a href=&#34;https://www.turing.ac.uk/research/publications/ai-human-rights-democracy-and-rule-law-primer-prepared-council-europe&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Primer&lt;/a&gt; that the Alan Turing Institute and the Council of Europe just published. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
